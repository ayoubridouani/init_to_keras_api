{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transfer Learning & Fine-Tuning.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPT7wxpKwzbHehiExJxRjUg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7ZFV-nFPgLOW","colab_type":"text"},"source":["References:\n","\n","https://keras.io/guides/transfer_learning/\n","\n","\n","\n","\n","\n","\n","**Transfer learning** consists of taking features learned on one problem, and leveraging them on a new, similar problem. For instance, features from a model that has learned to identify racoons may be useful to kick-start a model meant to identify tanukis.\n","\n","**fine-tuning** which consists of unfreezing the entire model you obtained above (or part of it), and re-training it on the new data with a very low learning rate."]},{"cell_type":"code","metadata":{"id":"gcL9MMp9lxlV","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import Dense,Input\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.applications import Xception\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O589KBPitOAX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1594400069893,"user_tz":-60,"elapsed":4832,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"74a922be-c283-4c31-bc88-55aa43e3dc81"},"source":["# Freezing layers: understanding the trainable attribute\n","layer = Dense(units=5)\n","layer.build(10)\n","\n","layer.trainable = True\n","print(\"weights:\", len(layer.weights))\n","print(\"trainable_weights:\", len(layer.trainable_weights))\n","print(\"non_trainable_weights:\", len(layer.non_trainable_weights))\n","\n","layer.trainable = False\n","print(\"weights:\", len(layer.weights))\n","print(\"trainable_weights:\", len(layer.trainable_weights))\n","print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["weights: 2\n","trainable_weights: 2\n","non_trainable_weights: 0\n","weights: 2\n","trainable_weights: 0\n","non_trainable_weights: 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CwyEdiSLtdvS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":208},"executionInfo":{"status":"ok","timestamp":1594400069895,"user_tz":-60,"elapsed":4805,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"7ea410ad-7e81-43e5-9373-4d061d47539d"},"source":["layer.get_weights()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[ 0.34438372, -0.10960078, -0.0829013 ,  0.43132752,  0.39637607],\n","        [-0.28892165,  0.15634978,  0.1124264 , -0.11049843,  0.30737466],\n","        [ 0.3237577 , -0.18090189,  0.23819059, -0.5063975 ,  0.4299615 ],\n","        [ 0.26807278, -0.415672  ,  0.45800513, -0.0847497 , -0.43254787],\n","        [ 0.439372  , -0.33280703, -0.28588083, -0.2069771 ,  0.36514604],\n","        [ 0.16605234, -0.4311357 ,  0.2676103 ,  0.10231072,  0.56260115],\n","        [-0.20577139,  0.35584807, -0.493136  , -0.382597  , -0.31366208],\n","        [-0.03944945,  0.1340285 ,  0.61397845, -0.09809119,  0.5924638 ],\n","        [ 0.20215517,  0.4350571 ,  0.08144724, -0.6234227 , -0.10029185],\n","        [ 0.54995435,  0.20072103,  0.05097967, -0.3460531 ,  0.33594483]],\n","       dtype=float32), array([0., 0., 0., 0., 0.], dtype=float32)]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"HJ29ukprtgv4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":260},"executionInfo":{"status":"ok","timestamp":1594400069899,"user_tz":-60,"elapsed":4780,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"59cf624a-2a81-4440-c427-5e8c72cffa74"},"source":["layer.get_config()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'activation': 'linear',\n"," 'activity_regularizer': None,\n"," 'bias_constraint': None,\n"," 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n"," 'bias_regularizer': None,\n"," 'dtype': 'float32',\n"," 'kernel_constraint': None,\n"," 'kernel_initializer': {'class_name': 'GlorotUniform',\n","  'config': {'seed': None}},\n"," 'kernel_regularizer': None,\n"," 'name': 'dense',\n"," 'trainable': False,\n"," 'units': 5,\n"," 'use_bias': True}"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"ML6xh_gD0lfh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594400069901,"user_tz":-60,"elapsed":4753,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"fa595204-9a8a-41a5-e065-9d1ecf2f687f"},"source":["layer.trainable_weights"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"P0h_I8a3utfr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":243},"executionInfo":{"status":"ok","timestamp":1594400069903,"user_tz":-60,"elapsed":4726,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"7dcabc56-43d6-4090-b3c2-baef3337bc1f"},"source":["layer.non_trainable_weights"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Variable 'kernel:0' shape=(10, 5) dtype=float32, numpy=\n"," array([[ 0.34438372, -0.10960078, -0.0829013 ,  0.43132752,  0.39637607],\n","        [-0.28892165,  0.15634978,  0.1124264 , -0.11049843,  0.30737466],\n","        [ 0.3237577 , -0.18090189,  0.23819059, -0.5063975 ,  0.4299615 ],\n","        [ 0.26807278, -0.415672  ,  0.45800513, -0.0847497 , -0.43254787],\n","        [ 0.439372  , -0.33280703, -0.28588083, -0.2069771 ,  0.36514604],\n","        [ 0.16605234, -0.4311357 ,  0.2676103 ,  0.10231072,  0.56260115],\n","        [-0.20577139,  0.35584807, -0.493136  , -0.382597  , -0.31366208],\n","        [-0.03944945,  0.1340285 ,  0.61397845, -0.09809119,  0.5924638 ],\n","        [ 0.20215517,  0.4350571 ,  0.08144724, -0.6234227 , -0.10029185],\n","        [ 0.54995435,  0.20072103,  0.05097967, -0.3460531 ,  0.33594483]],\n","       dtype=float32)>,\n"," <tf.Variable 'bias:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"LinXfJnFuv7j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":243},"executionInfo":{"status":"ok","timestamp":1594400069906,"user_tz":-60,"elapsed":4700,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"27d98528-5fb4-4c18-b2a7-9ebf88817307"},"source":["# Make a model with 2 layers\n","layer1 = Dense(3, activation=\"relu\")\n","layer2 = Dense(3, activation=\"sigmoid\")\n","model = Sequential([Input(shape=(3,)), layer1, layer2])\n","\n","# Freeze the first layer\n","layer1.trainable = False\n","\n","# Keep a copy of the weights of layer1,layer2 for later reference\n","initial_layer1_weights_values = layer1.get_weights()\n","initial_layer2_weights_values = layer2.get_weights()\n","\n","# Train the model\n","model.compile(optimizer=\"adam\", loss=\"mse\")\n","model.fit(np.random.random((2, 3)), np.random.random((2, 3)),epochs=1)\n","model.summary()\n","\n","# Check that the weights of layer1 have not changed during training\n","final_layer1_weights_values = layer1.get_weights()\n","final_layer2_weights_values = layer2.get_weights()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 0s 1ms/step - loss: 0.1289\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 3)                 12        \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 24\n","Trainable params: 12\n","Non-trainable params: 12\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0SzwQUpWvlsq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1594400069909,"user_tz":-60,"elapsed":4676,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"b8a26d3b-ee7c-4a00-8e9f-935cfdc8b42f"},"source":["initial_layer1_weights_values, \"----------------\", final_layer1_weights_values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([array([[-0.4503696 ,  0.35640144,  0.48098707],\n","         [ 0.6176903 , -0.6311712 ,  0.44780326],\n","         [ 0.16698074, -0.38884568,  0.88005114]], dtype=float32),\n","  array([0., 0., 0.], dtype=float32)],\n"," '----------------',\n"," [array([[-0.4503696 ,  0.35640144,  0.48098707],\n","         [ 0.6176903 , -0.6311712 ,  0.44780326],\n","         [ 0.16698074, -0.38884568,  0.88005114]], dtype=float32),\n","  array([0., 0., 0.], dtype=float32)])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"ddqW_qdWwAij","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1594400069912,"user_tz":-60,"elapsed":4652,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"2d9aee06-7599-4daa-c7f1-05191e6a818d"},"source":["initial_layer2_weights_values, \"----------------\", final_layer2_weights_values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([array([[-0.65224934,  0.9101398 , -0.8492899 ],\n","         [-0.1779542 ,  0.64869547, -0.7673514 ],\n","         [-0.80746555,  0.30677772,  0.69177675]], dtype=float32),\n","  array([0., 0., 0.], dtype=float32)],\n"," '----------------',\n"," [array([[-0.65224934,  0.9101398 , -0.8492899 ],\n","         [-0.17695488,  0.6476961 , -0.76835054],\n","         [-0.8064656 ,  0.3057778 ,  0.6907768 ]], dtype=float32),\n","  array([ 0.00099994, -0.00099994, -0.00099992], dtype=float32)])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"c26cZ3O0wW0a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"status":"ok","timestamp":1594400069914,"user_tz":-60,"elapsed":4628,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"979e6758-f19d-4f43-fe8d-f1d7813ccb7e"},"source":["inner_model = Sequential(\n","    [\n","        Input(shape=(3,)),\n","        Dense(3, activation=\"relu\"),\n","        Dense(3, activation=\"relu\"),\n","    ]\n",")\n","inner_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_3 (Dense)              (None, 3)                 12        \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 24\n","Trainable params: 24\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E2jcVEKoxtL7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"status":"ok","timestamp":1594400069915,"user_tz":-60,"elapsed":4602,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"069af735-3f31-4767-b34b-7dfe00d669c0"},"source":["model = Sequential(\n","    [Input(shape=(3,)), inner_model, Dense(3, activation=\"sigmoid\"),]\n",")\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","sequential_1 (Sequential)    (None, 3)                 24        \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 36\n","Trainable params: 36\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MymE9MMI2iP5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"status":"ok","timestamp":1594400069916,"user_tz":-60,"elapsed":4575,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"136368c2-4c79-49b4-9d99-91394dec0792"},"source":["inner_model.trainable = False\n","inner_model.summary()\n","print(\"\\n\\n\")\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_3 (Dense)              (None, 3)                 12        \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 24\n","Trainable params: 0\n","Non-trainable params: 24\n","_________________________________________________________________\n","\n","\n","\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","sequential_1 (Sequential)    (None, 3)                 24        \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 36\n","Trainable params: 12\n","Non-trainable params: 24\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WtQnVrNDkdiC","colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"status":"ok","timestamp":1594400069918,"user_tz":-60,"elapsed":4552,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"64902f57-c219-47f3-e95d-9e7acfc95318"},"source":["inner_model.trainable = True\n","inner_model.summary()\n","print(\"\\n\\n\")\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_3 (Dense)              (None, 3)                 12        \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 24\n","Trainable params: 24\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n","\n","\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","sequential_1 (Sequential)    (None, 3)                 24        \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 36\n","Trainable params: 36\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yMKMEFtG2e-t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"status":"ok","timestamp":1594400069928,"user_tz":-60,"elapsed":4535,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"c4f9a42f-218a-426e-d570-48bacae3ec81"},"source":["model.trainable = False  # Freeze the outer model\n","model.summary()\n","print(\"\\n\\n\")\n","inner_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","sequential_1 (Sequential)    (None, 3)                 24        \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 36\n","Trainable params: 0\n","Non-trainable params: 36\n","_________________________________________________________________\n","\n","\n","\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_3 (Dense)              (None, 3)                 12        \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 24\n","Trainable params: 0\n","Non-trainable params: 24\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h18U7KNG2lWO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"status":"ok","timestamp":1594400069930,"user_tz":-60,"elapsed":4512,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"97ab9bf9-0cdc-4d22-e0cb-2e084e8e1f6a"},"source":["inner_model.layers[0].trainable = True\n","inner_model.summary()\n","print(\"\\n\\n\")\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_3 (Dense)              (None, 3)                 12        \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 24\n","Trainable params: 0\n","Non-trainable params: 24\n","_________________________________________________________________\n","\n","\n","\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","sequential_1 (Sequential)    (None, 3)                 24        \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 36\n","Trainable params: 0\n","Non-trainable params: 36\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fo26BdDa5Zix","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"status":"ok","timestamp":1594400070520,"user_tz":-60,"elapsed":5076,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"8d7931ce-6b87-4226-81df-af33c22483e8"},"source":["model.layers[0].trainable = True\n","model.summary()\n","print(\"\\n\\n\")\n","inner_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","sequential_1 (Sequential)    (None, 3)                 24        \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 36\n","Trainable params: 0\n","Non-trainable params: 36\n","_________________________________________________________________\n","\n","\n","\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_3 (Dense)              (None, 3)                 12        \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 3)                 12        \n","=================================================================\n","Total params: 24\n","Trainable params: 24\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y9UMzYRAIjfJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594400073359,"user_tz":-60,"elapsed":7889,"user":{"displayName":"AYOUB RIDOUANI","photoUrl":"","userId":"02798743830054257250"}},"outputId":"67afc030-e73f-4fde-fffd-16958b008e26"},"source":["base_model = Xception(\n","    weights='imagenet',  # Load weights pre-trained on ImageNet.\n","    input_shape=(150, 150, 3),\n","    include_top=False)  # Do not include the ImageNet classifier at the top.\n","\n","base_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 150, 150, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_4[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 36, 36, 128)  512         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 36, 36, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 18, 18, 256)  32768       add[0][0]                        \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 18, 18, 256)  1024        conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 18, 18, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 9, 9, 728)    186368      add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 9, 9, 728)    2912        conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 9, 9, 728)    0           block4_pool[0][0]                \n","                                                                 batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n","                                                                 add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n","                                                                 add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n","                                                                 add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n","                                                                 add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n","                                                                 add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n","                                                                 add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n","                                                                 add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 5, 5, 1024)   745472      add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 5, 5, 1024)   4096        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_11[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n","==================================================================================================\n","Total params: 20,861,480\n","Trainable params: 20,806,952\n","Non-trainable params: 54,528\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ii-WMFN_lhXj","colab_type":"code","colab":{}},"source":["# Transfer Learning\n","\n","# Then, freeze the base model.\n","base_model.trainable = False\n","\n","# We make sure that the base_model is running in inference mode here,\n","# by passing `training=False`. This is important for fine-tuning, as you will\n","# learn in a few paragraphs.\n","x = base_model(inputs, training=False)\n","\n","# Convert features of shape `base_model.output_shape[1:]` to vectors\n","x = keras.layers.GlobalAveragePooling2D()(x)\n","\n","# A Dense classifier with a single unit (binary classification)\n","outputs = keras.layers.Dense(1)(x)\n","model = keras.Model(inputs, outputs)\n","\n","# Train the model on new data\n","model.compile(optimizer=keras.optimizers.Adam(),\n","              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=[keras.metrics.BinaryAccuracy()])\n","model.fit(new_dataset, epochs=20, callbacks=..., validation_data=...)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjt6PWsJn2F1","colab_type":"code","colab":{}},"source":["# Fine Tuning\n","\n","# Unfreeze the base model\n","base_model.trainable = True\n","\n","# It's important to recompile your model after you make any changes\n","# to the `trainable` attribute of any inner layer, so that your changes\n","# are take into account\n","model.compile(optimizer=keras.optimizers.Adam(1e-5),  # Very low learning rate\n","              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=[keras.metrics.BinaryAccuracy()])\n","\n","# Train end-to-end. Be careful to stop before you overfit!\n","model.fit(new_dataset, epochs=10, callbacks=..., validation_data=...)"],"execution_count":null,"outputs":[]}]}